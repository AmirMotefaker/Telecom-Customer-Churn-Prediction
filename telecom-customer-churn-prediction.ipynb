{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/amirmotefaker/telecom-customer-churn-prediction?scriptVersionId=144953740\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Telecom Customer Churn Prediction\n- Churn is a one of the biggest problem in the telecom industry. \n\n- For Telco companies it is key to attract new customers and at the same time avoid contract terminations to grow their revenue-generating base. Looking at churn, different reasons trigger customers to terminate their contracts, for example, better price offers more interesting packages, bad service experiences, or changes in customers’ personal situations.\n\n- Telcos apply machine learning models to predict churn on an individual customer basis and take countermeasures such as discounts, special offers, or other gratifications to keep their customers. A customer churn analysis is a typical classification problem within the domain of supervised learning.\n\n- Churn analytics provides valuable capabilities to predict customer churn and also define the underlying reasons that drive it. The churn metric is mostly shown as the percentage of customers that cancel a product or service within a given period (mostly months).\n\n- I have explored the following classficiation techniques and compared their accuracy and other metrics such as: \n   - ROC-AUC score\n   - True Positive Rate and False Positive Rate\n   \n### What is churn analytics?\n- Churn analytics is the process of measuring and understanding the rate at which customers quit the product, site, or service. \n- Churn analytics can help you understand how frequently customers churn out of the product and where this tends to occur. \n- Help you understand which features and functionality are important for keeping customers in your product. \n- Churn analytics is critical for getting a performance overview, identifying improvements and understanding which channels are driving the most value.\n\n\n- Customer churn is a major problem and one of the most important concerns for large companies. Due to the direct effect on the revenues of the companies, especially in the telecom field, companies are seeking to develop means to predict potential customer to churn. Therefore, finding factors that increase customer churn is important to take necessary actions to reduce this churn. The main contribution of our work is to develop a churn prediction model which assists telecom operators to predict customers who are most likely subject to churn. The model developed in this work uses machine learning techniques on big data platform and builds a new way of features’ engineering and selection. In order to measure the performance of the model, the Area Under Curve (AUC) standard measure is adopted, and the AUC value obtained is 93.3%. Another main contribution is to use customer social network in the prediction model by extracting Social Network Analysis (SNA) features. The use of SNA enhanced the performance of the model from 84 to 93.3% against AUC standard. The model was prepared and tested through Spark environment by working on a large dataset created by transforming big raw data provided by SyriaTel telecom company. The dataset contained all customers’ information over 9 months, and was used to train, test, and evaluate the system at SyriaTel. The model experimented four algorithms: Decision Tree, Random Forest, Gradient Boosted Machine Tree “GBM” and Extreme Gradient Boosting “XGBOOST”. However, the best results were obtained by applying XGBOOST algorithm. This algorithm was used for classification in this churn predictive model.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # For creating plots\nimport matplotlib.ticker as mtick # For specifying the axes tick format \nimport matplotlib.pyplot as plt\n\nsns.set(style = 'white')\n\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score\nfrom datetime import datetime\nimport lightgbm as lgbm # LightGBM is a gradient boosting framework that uses tree based learning algorithms. \nimport warnings\n\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nimport warnings\n\nfrom contextlib import contextmanager\n# @contextlib.contextmanager\n# This function is a decorator that can be used to define a factory function for with statement context managers,\n# without needing to create a class or separate __enter__() and __exit__() methods.\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n\nwarnings.filterwarnings('ignore') #ignore warning messages","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:07.269214Z","iopub.execute_input":"2023-10-02T09:52:07.269636Z","iopub.status.idle":"2023-10-02T09:52:08.500114Z","shell.execute_reply.started":"2023-10-02T09:52:07.269572Z","shell.execute_reply":"2023-10-02T09:52:08.49881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/telcom-customer-churn/Telco-Customer-Churn.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.502213Z","iopub.execute_input":"2023-10-02T09:52:08.502631Z","iopub.status.idle":"2023-10-02T09:52:08.535335Z","shell.execute_reply.started":"2023-10-02T09:52:08.5026Z","shell.execute_reply":"2023-10-02T09:52:08.533946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.536852Z","iopub.execute_input":"2023-10-02T09:52:08.537282Z","iopub.status.idle":"2023-10-02T09:52:08.566431Z","shell.execute_reply.started":"2023-10-02T09:52:08.537243Z","shell.execute_reply":"2023-10-02T09:52:08.565116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns.values","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.567654Z","iopub.execute_input":"2023-10-02T09:52:08.568006Z","iopub.status.idle":"2023-10-02T09:52:08.5767Z","shell.execute_reply.started":"2023-10-02T09:52:08.567976Z","shell.execute_reply":"2023-10-02T09:52:08.575049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the data types of all the columns\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.580172Z","iopub.execute_input":"2023-10-02T09:52:08.580507Z","iopub.status.idle":"2023-10-02T09:52:08.593642Z","shell.execute_reply.started":"2023-10-02T09:52:08.580486Z","shell.execute_reply":"2023-10-02T09:52:08.593019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting Total Charges to a numerical data type.\ndata.TotalCharges = pd.to_numeric(data.TotalCharges, errors='coerce')\ndata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.59479Z","iopub.execute_input":"2023-10-02T09:52:08.595163Z","iopub.status.idle":"2023-10-02T09:52:08.622164Z","shell.execute_reply.started":"2023-10-02T09:52:08.595141Z","shell.execute_reply":"2023-10-02T09:52:08.620424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing missing values \ndata.dropna(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.623963Z","iopub.execute_input":"2023-10-02T09:52:08.624412Z","iopub.status.idle":"2023-10-02T09:52:08.651987Z","shell.execute_reply.started":"2023-10-02T09:52:08.624388Z","shell.execute_reply":"2023-10-02T09:52:08.650295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove customer IDs from the data set\ndf2 = data.iloc[:,1:]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.653933Z","iopub.execute_input":"2023-10-02T09:52:08.654554Z","iopub.status.idle":"2023-10-02T09:52:08.665194Z","shell.execute_reply.started":"2023-10-02T09:52:08.654518Z","shell.execute_reply":"2023-10-02T09:52:08.664167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convertin the predictor variable in a binary numeric variable\ndf2['Churn'].replace(to_replace='Yes', value=1, inplace=True)\ndf2['Churn'].replace(to_replace='No',  value=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.666461Z","iopub.execute_input":"2023-10-02T09:52:08.66685Z","iopub.status.idle":"2023-10-02T09:52:08.687016Z","shell.execute_reply.started":"2023-10-02T09:52:08.666823Z","shell.execute_reply":"2023-10-02T09:52:08.68563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's convert all the categorical variables into dummy variables\ndf_dummies = pd.get_dummies(df2)\ndf_dummies.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.68859Z","iopub.execute_input":"2023-10-02T09:52:08.68897Z","iopub.status.idle":"2023-10-02T09:52:08.737511Z","shell.execute_reply.started":"2023-10-02T09:52:08.688945Z","shell.execute_reply":"2023-10-02T09:52:08.736044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get Correlation of \"Churn\" with other variables:\nplt.figure(figsize=(15,8))\ndf_dummies.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:08.739961Z","iopub.execute_input":"2023-10-02T09:52:08.741158Z","iopub.status.idle":"2023-10-02T09:52:09.357504Z","shell.execute_reply.started":"2023-10-02T09:52:08.741122Z","shell.execute_reply":"2023-10-02T09:52:09.355924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Contracts month to month, absence of online security and tech support seem to be positively correlated with churn.\n\n- Tenure, two year contracts seem to be negatively correlated with churn.\n\n- Services such as Online security, streaming TV, online backup, tech support, etc. without internet connection seem to be negatively related to churn.","metadata":{}},{"cell_type":"markdown","source":"# A.) Demographics - Let us first understand the gender, age range, partner, and dependent status of the customers.","metadata":{}},{"cell_type":"markdown","source":"## 1. Gender Distribution","metadata":{}},{"cell_type":"code","source":"colors = ['#4D3425','#E4512B']\nax = (data['gender'].value_counts()*100.0 /len(data)).plot(kind='bar',\n                                                           stacked = True,\n                                                           rot = 0,\n                                                           color = colors)\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('% Customers')\nax.set_xlabel('Gender')\nax.set_ylabel('% Customers')\nax.set_title('Gender Distribution')\n\n# create a list to collect the plt.patches data\ntotals = []\n\n# find the values and append to list\nfor i in ax.patches:\n    totals.append(i.get_width())\n\n# set individual bar lables using above list\ntotal = sum(totals)\n\nfor i in ax.patches:\n    # get_width pulls left or right; get_y pushes up or down\n    ax.text(i.get_x()+.15, i.get_height()-3.5, \\\n            str(round((i.get_height()/total), 1))+'%',\n            fontsize=12,\n            color='white',\n            weight = 'bold')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:09.358695Z","iopub.execute_input":"2023-10-02T09:52:09.359314Z","iopub.status.idle":"2023-10-02T09:52:09.49454Z","shell.execute_reply.started":"2023-10-02T09:52:09.359287Z","shell.execute_reply":"2023-10-02T09:52:09.493842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- About half of the customers in our data set are male while the other half are female","metadata":{}},{"cell_type":"markdown","source":"## 2. % Senior Citizens","metadata":{}},{"cell_type":"code","source":"ax = (data['SeniorCitizen'].value_counts()*100.0 /len(data))\\\n.plot.pie(autopct='%.1f%%', labels = ['No', 'Yes'],figsize =(5,5), fontsize = 12 )                                                                           \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('Senior Citizens',fontsize = 12)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:09.495564Z","iopub.execute_input":"2023-10-02T09:52:09.496179Z","iopub.status.idle":"2023-10-02T09:52:09.570679Z","shell.execute_reply.started":"2023-10-02T09:52:09.496153Z","shell.execute_reply":"2023-10-02T09:52:09.569963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There are only 16% of the customers who are senior citizens. Thus most of our customers in the data are younger people.","metadata":{}},{"cell_type":"markdown","source":"## 3. Partner and dependent status","metadata":{}},{"cell_type":"code","source":"df2 = pd.melt(data, id_vars=['customerID'], value_vars=['Dependents','Partner'])\ndf3 = df2.groupby(['variable','value']).count().unstack()\ndf3 = df3*100/len(data)\ncolors = ['#4D3425','#E4512B']\nax = df3.loc[:,'customerID'].plot.bar(stacked=True, color=colors,\n                                      figsize=(8,6),rot = 0,\n                                      width = 0.2)\n\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('% Customers',size = 14)\nax.set_xlabel('')\nax.set_title('% Customers with dependents and partners',size = 14)\nax.legend(loc = 'center',prop={'size':14})\n\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate('{:.0f}%'.format(height), (p.get_x()+.25*width, p.get_y()+.4*height),\n                color = 'white',\n                weight = 'bold',\n                size = 14)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:09.571951Z","iopub.execute_input":"2023-10-02T09:52:09.57237Z","iopub.status.idle":"2023-10-02T09:52:09.75217Z","shell.execute_reply.started":"2023-10-02T09:52:09.572345Z","shell.execute_reply":"2023-10-02T09:52:09.751222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- About 50% of the customers have a partner, while only 30% of the total customers have dependents.","metadata":{}},{"cell_type":"markdown","source":"- What would be interesting is to look at the % of customers, who have partners, also have dependents. We will explore this next.\n\n- Interestingly, among the customers who have a partner, only about half of them also have a dependent, while the other half do not have any independents. Additionally, as expected, among the customers who do not have any partner, a majority (80%) of them do not have any dependents.","metadata":{}},{"cell_type":"code","source":"colors = ['#4D3425','#E4512B']\npartner_dependents = data.groupby(['Partner','Dependents']).size().unstack()\n\nax = (partner_dependents.T*100.0 / partner_dependents.T.sum()).T.plot(kind='bar',\n                                                                      width = 0.2,\n                                                                      stacked = True,\n                                                                      rot = 0, \n                                                                      figsize = (8,6),\n                                                                      color = colors)\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.legend(loc='center',prop={'size':14},title = 'Dependents',fontsize =14)\nax.set_ylabel('% Customers',size = 14)\nax.set_title('% Customers with/without dependents based on whether they have a partner',size = 14)\nax.xaxis.label.set_size(14)\n\n# Code to add the data labels on the stacked bar chart\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate('{:.0f}%'.format(height), (p.get_x()+.25*width, p.get_y()+.4*height),\n                color = 'white',\n                weight = 'bold',\n                size = 14)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:09.754039Z","iopub.execute_input":"2023-10-02T09:52:09.754588Z","iopub.status.idle":"2023-10-02T09:52:09.944987Z","shell.execute_reply.started":"2023-10-02T09:52:09.754563Z","shell.execute_reply":"2023-10-02T09:52:09.943569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- I also looked at any differences between the % of customers with/without dependents and partners by gender. There is no difference in their distribution by gender.\n- Additionally, there is no difference in senior citizen status by gender.","metadata":{}},{"cell_type":"markdown","source":"# B.) Customer Account Information","metadata":{}},{"cell_type":"markdown","source":"### 1.Tenure","metadata":{}},{"cell_type":"code","source":"ax = sns.distplot(data['tenure'], hist=True, kde=False, \n             bins=int(180/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('Tenure (months)')\nax.set_title('# of Customers by their tenure')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:09.946275Z","iopub.execute_input":"2023-10-02T09:52:09.946859Z","iopub.status.idle":"2023-10-02T09:52:10.222261Z","shell.execute_reply.started":"2023-10-02T09:52:09.946822Z","shell.execute_reply":"2023-10-02T09:52:10.221065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Looking at the above histogram we can see that a lot of customers have been with the telecom company for just a month, while quite a many are there for about 72 months. This could be potentially because different customers have different contracts. Thus based on the contract they are into it could be more/less easier for the customers to stay/leave the telecom company.","metadata":{}},{"cell_type":"markdown","source":"### 2. Contracts:\n- To understand the above graph, lets first look at the # of customers by different contracts.","metadata":{}},{"cell_type":"code","source":"ax = data['Contract'].value_counts().plot(kind = 'bar',rot = 0, width = 0.3)\nax.set_ylabel('# of Customers')\nax.set_title('# of Customers by Contract Type')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:10.226292Z","iopub.execute_input":"2023-10-02T09:52:10.227121Z","iopub.status.idle":"2023-10-02T09:52:10.379633Z","shell.execute_reply.started":"2023-10-02T09:52:10.227089Z","shell.execute_reply":"2023-10-02T09:52:10.3788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we can see from this graph most of the customers are in the month-to-month contract. While there are an equal number of customers in the 1 year and 2-year contracts.","metadata":{}},{"cell_type":"markdown","source":"### Now, we will understand the tenure of customers based on their contract type:","metadata":{}},{"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, sharey = True, figsize = (20,6))\n\nax = sns.distplot(data[data['Contract']=='Month-to-month']['tenure'],\n                   hist=True, kde=False,\n                   bins=int(180/5), color = 'turquoise',\n                   hist_kws={'edgecolor':'black'},\n                   kde_kws={'linewidth': 4},\n                 ax=ax1)\nax.set_ylabel('# of Customers')\nax.set_xlabel('Tenure (months)')\nax.set_title('Month to Month Contract')\n\nax = sns.distplot(data[data['Contract']=='One year']['tenure'],\n                   hist=True, kde=False,\n                   bins=int(180/5), color = 'steelblue',\n                   hist_kws={'edgecolor':'black'},\n                   kde_kws={'linewidth': 4},\n                 ax=ax2)\nax.set_xlabel('Tenure (months)',size = 14)\nax.set_title('One Year Contract',size = 14)\n\nax = sns.distplot(data[data['Contract']=='Two year']['tenure'],\n                   hist=True, kde=False,\n                   bins=int(180/5), color = 'darkblue',\n                   hist_kws={'edgecolor':'black'},\n                   kde_kws={'linewidth': 4},\n                 ax=ax3)\n\nax.set_xlabel('Tenure (months)')\nax.set_title('Two Year Contract')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:10.380686Z","iopub.execute_input":"2023-10-02T09:52:10.380972Z","iopub.status.idle":"2023-10-02T09:52:10.979421Z","shell.execute_reply.started":"2023-10-02T09:52:10.380951Z","shell.execute_reply":"2023-10-02T09:52:10.978416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Most of the monthly contracts last for 1-2 months, while the 2 year contracts tend to last for about 70 months.\n\n- This shows that the customers taking a longer contract are more loyal to the company and tend to stay with it for a longer period of time.\n\n- This is also what we saw in the earlier chart on correlation with the churn rate.","metadata":{}},{"cell_type":"markdown","source":"# C.) Distribution of various services used by customers","metadata":{}},{"cell_type":"code","source":"services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',\n           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n\nfig, axes = plt.subplots(nrows = 3,ncols = 3,figsize = (15,12))\nfor i, item in enumerate(services):\n    if i < 3:\n        ax = data[item].value_counts().plot(kind = 'bar',ax=axes[i,0],rot = 0)\n        \n    elif i >=3 and i < 6:\n        ax = data[item].value_counts().plot(kind = 'bar',ax=axes[i-3,1],rot = 0)\n        \n    elif i < 9:\n        ax = data[item].value_counts().plot(kind = 'bar',ax=axes[i-6,2],rot = 0)\n    ax.set_title(item)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:10.980392Z","iopub.execute_input":"2023-10-02T09:52:10.981216Z","iopub.status.idle":"2023-10-02T09:52:11.843553Z","shell.execute_reply.started":"2023-10-02T09:52:10.981191Z","shell.execute_reply":"2023-10-02T09:52:11.842573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# D.) Relation between monthly and total charges","metadata":{}},{"cell_type":"code","source":"data[['MonthlyCharges', 'TotalCharges']].plot.scatter(x = 'MonthlyCharges',\n                                                      y='TotalCharges')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:11.844755Z","iopub.execute_input":"2023-10-02T09:52:11.845016Z","iopub.status.idle":"2023-10-02T09:52:12.056094Z","shell.execute_reply.started":"2023-10-02T09:52:11.844995Z","shell.execute_reply":"2023-10-02T09:52:12.055004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Observe that the total charges increase as the monthly bill for a customer increases.","metadata":{}},{"cell_type":"markdown","source":"# E.) Predictor variable (Churn) and interaction with other important variables.","metadata":{}},{"cell_type":"code","source":"colors = ['#4D3425','#E4512B']\nax = (data['Churn'].value_counts()*100.0 /len(data)).plot(kind='bar',\n                                                                           stacked = True,\n                                                                           rot = 0,\n                                                                           color = colors,\n                                                                           figsize = (8,6))\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('% Customers',size = 14)\nax.set_xlabel('Churn',size = 14)\nax.set_title('Churn Rate', size = 14)\n\n# create a list to collect the plt.patches data\ntotals = []\n\n# find the values and append to list\nfor i in ax.patches:\n    totals.append(i.get_width())\n\n# set individual bar lables using above list\ntotal = sum(totals)\n\nfor i in ax.patches:\n    # get_width pulls left or right; get_y pushes up or down\n    ax.text(i.get_x()+.15, i.get_height()-4.0, \\\n            str(round((i.get_height()/total), 1))+'%',\n            color='white',\n            weight = 'bold',\n            size = 14)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:12.05793Z","iopub.execute_input":"2023-10-02T09:52:12.058511Z","iopub.status.idle":"2023-10-02T09:52:12.403327Z","shell.execute_reply.started":"2023-10-02T09:52:12.058475Z","shell.execute_reply":"2023-10-02T09:52:12.402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In above data, 74% of the customers do not churn.\n- Clearly the data is skewed as we would expect a large majority of the customers to not churn.\n- This is important to keep in mind for our modelling as skeweness could lead to a lot of false negatives.","metadata":{}},{"cell_type":"markdown","source":"### 1.) Churn vs Tenure: Explore the churn rate by tenure, seniority, contract type, monthly charges and total charges to see how it varies by these variables.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x = data.Churn, y = data.tenure)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:12.404622Z","iopub.execute_input":"2023-10-02T09:52:12.404985Z","iopub.status.idle":"2023-10-02T09:52:12.560147Z","shell.execute_reply.started":"2023-10-02T09:52:12.404958Z","shell.execute_reply":"2023-10-02T09:52:12.558945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As we can see form the above plot, the customers who do not churn, they tend to stay for a longer tenure with the telecom company.","metadata":{}},{"cell_type":"markdown","source":"### 2.) Churn by Contract Type:","metadata":{}},{"cell_type":"code","source":"colors = ['#4D3425','#E4512B']\ncontract_churn = data.groupby(['Contract','Churn']).size().unstack()\n\nax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n                                                                width = 0.3,\n                                                                stacked = True,\n                                                                rot = 0, \n                                                                figsize = (10,6),\n                                                                color = colors)\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.legend(loc='best',prop={'size':14},title = 'Churn')\nax.set_ylabel('% Customers',size = 14)\nax.set_title('Churn by Contract Type',size = 14)\n\n# Code to add the data labels on the stacked bar chart\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate('{:.0f}%'.format(height), (p.get_x()+.25*width, p.get_y()+.4*height),\n                color = 'white',\n                weight = 'bold',\n                size = 14)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:12.562267Z","iopub.execute_input":"2023-10-02T09:52:12.562598Z","iopub.status.idle":"2023-10-02T09:52:12.737077Z","shell.execute_reply.started":"2023-10-02T09:52:12.562569Z","shell.execute_reply":"2023-10-02T09:52:12.735501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Similar to what we saw in the correlation plot, the customers who have a month to month contract have a very high churn rate.","metadata":{}},{"cell_type":"markdown","source":"### 3.) Churn by Seniority Level:","metadata":{}},{"cell_type":"code","source":"colors = ['#4D3425','#E4512B']\nseniority_churn = data.groupby(['SeniorCitizen','Churn']).size().unstack()\n\nax = (seniority_churn.T*100.0 / seniority_churn.T.sum()).T.plot(kind='bar',\n                                                                width = 0.2,\n                                                                stacked = True,\n                                                                rot = 0, \n                                                                figsize = (8,6),\n                                                                color = colors)\nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.legend(loc='center',prop={'size':14},title = 'Churn')\nax.set_ylabel('% Customers')\nax.set_title('Churn by Seniority Level',size = 14)\n\n# Code to add the data labels on the stacked bar chart\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate('{:.0f}%'.format(height), (p.get_x()+.25*width, p.get_y()+.4*height),\n                color = 'white',\n                weight = 'bold',size =14)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:12.738356Z","iopub.execute_input":"2023-10-02T09:52:12.738675Z","iopub.status.idle":"2023-10-02T09:52:12.89137Z","shell.execute_reply.started":"2023-10-02T09:52:12.738645Z","shell.execute_reply":"2023-10-02T09:52:12.89015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.) Churn by Monthly Charges:","metadata":{}},{"cell_type":"code","source":"ax = sns.kdeplot(data.MonthlyCharges[(data[\"Churn\"] == 'No') ],\n                color=\"Red\", shade = True)\nax = sns.kdeplot(data.MonthlyCharges[(data[\"Churn\"] == 'Yes') ],\n                ax =ax, color=\"Blue\", shade= True)\nax.legend([\"Not Churn\",\"Churn\"],loc='upper right')\nax.set_ylabel('Density')\nax.set_xlabel('Monthly Charges')\nax.set_title('Distribution of monthly charges by churn')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:12.89248Z","iopub.execute_input":"2023-10-02T09:52:12.892947Z","iopub.status.idle":"2023-10-02T09:52:13.147096Z","shell.execute_reply.started":"2023-10-02T09:52:12.892919Z","shell.execute_reply":"2023-10-02T09:52:13.146025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Higher % of customers churn when the monthly charges are high.","metadata":{}},{"cell_type":"markdown","source":"### 5.) Churn by Total Charges:","metadata":{}},{"cell_type":"code","source":"ax = sns.kdeplot(data.TotalCharges[(data[\"Churn\"] == 'No') ],\n                color=\"Red\", shade = True)\nax = sns.kdeplot(data.TotalCharges[(data[\"Churn\"] == 'Yes') ],\n                ax =ax, color=\"Blue\", shade= True)\nax.legend([\"Not Churn\",\"Churn\"],loc='upper right')\nax.set_ylabel('Density')\nax.set_xlabel('Total Charges')\nax.set_title('Distribution of total charges by churn')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.148358Z","iopub.execute_input":"2023-10-02T09:52:13.14885Z","iopub.status.idle":"2023-10-02T09:52:13.381067Z","shell.execute_reply.started":"2023-10-02T09:52:13.148821Z","shell.execute_reply":"2023-10-02T09:52:13.380362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There is higher churn when the total charges are lower.","metadata":{}},{"cell_type":"markdown","source":"# Scaling the data","metadata":{}},{"cell_type":"markdown","source":"### We will use the data frame where we had created dummy variables:\n","metadata":{}},{"cell_type":"code","source":"y = df_dummies['Churn'].values\nX = df_dummies.drop(columns = ['Churn'])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.382365Z","iopub.execute_input":"2023-10-02T09:52:13.382852Z","iopub.status.idle":"2023-10-02T09:52:13.389801Z","shell.execute_reply.started":"2023-10-02T09:52:13.382828Z","shell.execute_reply":"2023-10-02T09:52:13.388009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling all the variables to a range of 0 to 1:","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfeatures = X.columns.values\nscaler = MinMaxScaler(feature_range = (0,1))\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X))\nX.columns = features","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.391478Z","iopub.execute_input":"2023-10-02T09:52:13.391849Z","iopub.status.idle":"2023-10-02T09:52:13.412889Z","shell.execute_reply.started":"2023-10-02T09:52:13.391821Z","shell.execute_reply":"2023-10-02T09:52:13.411472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It is essential to scale the variables in logistic regression so that they are within a range of 0 to 1.\n- This helped us improve the accuracy from 79.7% to 80.7%. Further, you will notice below that the importance of variables is also aligned with what we see in the Random Forest algorithm and the EDA we conducted above.","metadata":{}},{"cell_type":"markdown","source":"### Create Train & Test Data:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.41421Z","iopub.execute_input":"2023-10-02T09:52:13.414498Z","iopub.status.idle":"2023-10-02T09:52:13.432482Z","shell.execute_reply.started":"2023-10-02T09:52:13.414469Z","shell.execute_reply":"2023-10-02T09:52:13.43104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the Accuracy, Confusion Matrix, ROC Curve, ROC-AUC score and TPR/FPR rate also called as Specificity & Sensitivity\n\n### 1. Accuracy - It is calculated on the test data set\n\n### 2. Confusion Matrix - It tells us how many True Positive/True Negatives and False Positives/False Negatives are present in the prediction\n\n    a. TP: Number of customers who will actually default also predicted as default\n\n    b. TN: Number of customers who won't actually default also predicted as no default\n\n    c. FP: Number of customers who won't actually default but predicted as default\n\n    d. FN: Number of customers who will actually default but predicted as no default\n\n- Note: It is important for a Telecom company to know more about the customers who are likely to default. Thus it is fine to have more False Positives (FP's), however we must have a lower # of FN, because this will predict more risky customers to be not that risky. This is important to keep in mind as we evaluate al the different classification models. We shoud choose the right threshold (even if it eans reducing the accuracy a bit to get better TPR).\n\n### 3. ROC curve - It is a plot between Sensitivity and 1-Specificity predictions for all the different thresholds\n\n### 4. ROC-AUC score - It is the area under the ROC curve. It helps us compare different models. Higher AUC implies a better model.","metadata":{}},{"cell_type":"markdown","source":"# Function to print acuracy score, ROC curvey, ROC-AUC score and confusion matrix","metadata":{}},{"cell_type":"code","source":"def model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n    Precision =  (tp/(tp+fp))\n    Recall    =  (tp/(tp+fn))\n    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                    y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto', textfont=dict(color='black'),\n                    orientation = 'h', opacity = 1, marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #Roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #Feature importance\n    coefficients  = pd.DataFrame(eval(model).feature_importances_)\n    column_data   = pd.DataFrame(list(data))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace6 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\", \n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #Cumulative gain\n    pos = pd.get_dummies(y_test).values\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size / n \n    #plots\n    model = model\n    trace7 = go.Scatter(x = size,y = recall,\n                        line = dict(color = ('gold'),width = 2), fill='tozeroy') \n    \n    #Subplots\n    fig = tls.make_subplots(rows=4, cols=2, print_grid=False,\n                          specs=[[{}, {}], \n                                 [{}, {}],\n                                 [{'colspan': 2}, None],\n                                 [{'colspan': 2}, None]],\n                          subplot_titles=('Confusion Matrix',\n                                          'Metrics',\n                                          'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                          'Precision - Recall curve',\n                                          'Cumulative gains curve',\n                                          'Feature importance'\n                                          ))\n    \n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    fig.append_trace(trace6,4,1)\n    fig.append_trace(trace7,3,1)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report</b><br>'+str(model),\n                        autosize = False, height = 1500,width = 830,\n                        plot_bgcolor = 'black',\n                        paper_bgcolor = 'black',\n                        margin = dict(b = 195), font=dict(color='white'))\n    fig[\"layout\"][\"xaxis1\"].update(color = 'white')\n    fig[\"layout\"][\"yaxis1\"].update(color = 'white')\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1], color = 'white')))\n    fig[\"layout\"][\"yaxis2\"].update(color = 'white')\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"), color = 'white')\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"),color = 'white')\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05],color = 'white')\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05],color = 'white')\n    fig[\"layout\"][\"xaxis5\"].update(dict(title = \"Percentage contacted\"),color = 'white')\n    fig[\"layout\"][\"yaxis5\"].update(dict(title = \"Percentage positive targeted\"),color = 'white')\n    fig[\"layout\"][\"xaxis6\"].update(color = 'white')\n    fig[\"layout\"][\"yaxis6\"].update(color = 'white')\n    for i in fig['layout']['annotations']:\n        i['font'] = titlefont=dict(color='white', size = 14)\n    py.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.434341Z","iopub.execute_input":"2023-10-02T09:52:13.434761Z","iopub.status.idle":"2023-10-02T09:52:13.457477Z","shell.execute_reply.started":"2023-10-02T09:52:13.434725Z","shell.execute_reply":"2023-10-02T09:52:13.456063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function for Cross Validation","metadata":{}},{"cell_type":"code","source":"# Cross Validation metric\ndef cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.458747Z","iopub.execute_input":"2023-10-02T09:52:13.459024Z","iopub.status.idle":"2023-10-02T09:52:13.48114Z","shell.execute_reply.started":"2023-10-02T09:52:13.459002Z","shell.execute_reply":"2023-10-02T09:52:13.480237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Train & Test Data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.482065Z","iopub.execute_input":"2023-10-02T09:52:13.48284Z","iopub.status.idle":"2023-10-02T09:52:13.511038Z","shell.execute_reply.started":"2023-10-02T09:52:13.4828Z","shell.execute_reply":"2023-10-02T09:52:13.509382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Light GBM Without Hyperparameter Tuning\n- Light GBM(Light Gradient Boosting Machine): A fast, distributed, high performance gradient boosting (GBT, GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking, classification and many other machine learning tasks.","metadata":{}},{"cell_type":"code","source":"%%time\nlgbm_clf = lgbm.LGBMClassifier(n_estimators=1500, random_state = 42)\n\nlgbm_clf.fit(X_train, y_train)\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]\n\nmodel_performance('lgbm_clf')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:13.512879Z","iopub.execute_input":"2023-10-02T09:52:13.513238Z","iopub.status.idle":"2023-10-02T09:52:17.393927Z","shell.execute_reply.started":"2023-10-02T09:52:13.513212Z","shell.execute_reply":"2023-10-02T09:52:17.392798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Randomized GridSearch","metadata":{}},{"cell_type":"code","source":"random_state = 42","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:17.39503Z","iopub.execute_input":"2023-10-02T09:52:17.395416Z","iopub.status.idle":"2023-10-02T09:52:17.39841Z","shell.execute_reply.started":"2023-10-02T09:52:17.395394Z","shell.execute_reply":"2023-10-02T09:52:17.39779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_params = {\"early_stopping_rounds\" : 50, \n             \"eval_metric\" : 'binary', \n             \"eval_set\" : [(X_test,y_test)],\n             'eval_names': ['valid'],\n             'verbose': 0,\n             'categorical_feature': 'auto'}\n\nparam_test = {'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3, 0.4],\n              'n_estimators' : [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000, 3000, 5000],\n              'num_leaves': sp_randint(6, 50), \n              'min_child_samples': sp_randint(100, 500), \n              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n              'subsample': sp_uniform(loc=0.2, scale=0.8), \n              'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n              'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n              'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n              'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\n#number of combinations\nn_iter = 200\n\n#intialize lgbm and lunch the search\nlgbm_clf = lgbm.LGBMClassifier(random_state=random_state, silent=True, metric='None', n_jobs=4)\ngrid_search = RandomizedSearchCV(\n    estimator=lgbm_clf, param_distributions=param_test, \n    n_iter=n_iter,\n    scoring='accuracy',\n    cv=5,\n    refit=True,\n    random_state=random_state,\n    verbose=True)\n\ngrid_search.fit(X_train, y_train, **fit_params)\nprint('Best params: {} '.format(grid_search.best_params_))\n\nopt_parameters =  grid_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:52:17.399749Z","iopub.execute_input":"2023-10-02T09:52:17.399974Z","iopub.status.idle":"2023-10-02T09:54:36.348114Z","shell.execute_reply.started":"2023-10-02T09:52:17.399954Z","shell.execute_reply":"2023-10-02T09:54:36.346854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Light GBM after Random Gridsearch","metadata":{}},{"cell_type":"code","source":"%%time\nlgbm_clf = lgbm.LGBMClassifier(**opt_parameters)\n\nlgbm_clf.fit(X_train, y_train)\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]\n\nmodel_performance('lgbm_clf')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:36.350049Z","iopub.execute_input":"2023-10-02T09:54:36.350405Z","iopub.status.idle":"2023-10-02T09:54:37.146654Z","shell.execute_reply.started":"2023-10-02T09:54:36.350378Z","shell.execute_reply":"2023-10-02T09:54:37.145127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross Validation Light GBM ( 5CVs)","metadata":{}},{"cell_type":"code","source":"cross_val_metrics(lgbm_clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:37.147928Z","iopub.execute_input":"2023-10-02T09:54:37.148668Z","iopub.status.idle":"2023-10-02T09:54:46.254917Z","shell.execute_reply.started":"2023-10-02T09:54:37.148635Z","shell.execute_reply":"2023-10-02T09:54:46.254269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Defining function for Logistic Regression\ndef model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    # Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)/(tp+tn+fp+fn))\n    Precision =  (tp/(tp+fp))\n    Recall    =  (tp/(tp+fn))\n    F1_score  =  (2*(((tp/(tp+fp))*(tp/(tp+fn)))/((tp/(tp+fp))+(tp/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                    y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto', textfont=dict(color='black'),\n                    orientation = 'h', opacity = 1, marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    # Roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n#     #Feature importance\n#     coefficients  = pd.DataFrame(eval(model).feature_importances_)\n#     column_data   = pd.DataFrame(list(data))\n#     coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n#                               right_index= True, how = \"left\"))\n#     coef_sumry.columns = [\"coefficients\",\"features\"]\n#     coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n#     coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n#     trace6 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n#                     name = \"coefficients\", \n#                     marker = dict(color = coef_sumry[\"coefficients\"],\n#                                   colorscale = \"Viridis\",\n#                                   line = dict(width = .6,color = \"black\")))\n    \n    # Cumulative gain\n    pos = pd.get_dummies(y_test).values\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size / n \n    #plots\n    model = model\n    trace7 = go.Scatter(x = size,y = recall,\n                        line = dict(color = ('gold'),width = 2), fill='tozeroy') \n    \n    # Subplots\n    fig = tls.make_subplots(rows=3, cols=2, print_grid=False,\n                          specs=[[{}, {}], \n                                 [{}, {}],\n                                 [{'colspan': 2}, None]],\n                          subplot_titles=('Confusion Matrix',\n                                          'Metrics',\n                                          'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                          'Precision - Recall curve',\n                                          'Cumulative gains curve'\n                                          ))\n    \n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    #fig.append_trace(trace6,4,1)\n    fig.append_trace(trace7,3,1)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report</b><br>'+str(model),\n                        autosize = False, height = 1500,width = 830,\n                        plot_bgcolor = 'black',\n                        paper_bgcolor = 'black',\n                        margin = dict(b = 195), font=dict(color='white'))\n    fig[\"layout\"][\"xaxis1\"].update(color = 'white')\n    fig[\"layout\"][\"yaxis1\"].update(color = 'white')\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1], color = 'white')))\n    fig[\"layout\"][\"yaxis2\"].update(color = 'white')\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"), color = 'white')\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"),color = 'white')\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05],color = 'white')\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05],color = 'white')\n    fig[\"layout\"][\"xaxis5\"].update(dict(title = \"Percentage contacted\"),color = 'white')\n    fig[\"layout\"][\"yaxis5\"].update(dict(title = \"Percentage positive targeted\"),color = 'white')\n    #fig[\"layout\"][\"xaxis6\"].update(color = 'white')\n    #fig[\"layout\"][\"yaxis6\"].update(color = 'white')\n    for i in fig['layout']['annotations']:\n        i['font'] = titlefont=dict(color='white', size = 14)\n    py.iplot(fig)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:46.256456Z","iopub.execute_input":"2023-10-02T09:54:46.256758Z","iopub.status.idle":"2023-10-02T09:54:46.28174Z","shell.execute_reply.started":"2023-10-02T09:54:46.256729Z","shell.execute_reply":"2023-10-02T09:54:46.279919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running logistic regression model\nfrom sklearn.linear_model import LogisticRegression\n\nlgr_clf = LogisticRegression()\nlgr_clf.fit(X_train, y_train)\ny_pred = lgr_clf.predict(X_test)\ny_score = lgr_clf.predict_proba(X_test)[:,1]\n\nmodel_performance('lgr_clf')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:46.28307Z","iopub.execute_input":"2023-10-02T09:54:46.283576Z","iopub.status.idle":"2023-10-02T09:54:46.556346Z","shell.execute_reply.started":"2023-10-02T09:54:46.28354Z","shell.execute_reply":"2023-10-02T09:54:46.5555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_val_metrics(lgr_clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:46.558111Z","iopub.execute_input":"2023-10-02T09:54:46.558655Z","iopub.status.idle":"2023-10-02T09:54:48.580243Z","shell.execute_reply.started":"2023-10-02T09:54:46.558618Z","shell.execute_reply":"2023-10-02T09:54:48.579562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. AdaBoost","metadata":{}},{"cell_type":"code","source":"# AdaBoost Algorithm\nfrom sklearn.ensemble import AdaBoostClassifier\n\nadb_clf = AdaBoostClassifier()\n# n_estimators = 50 (default value) \n# base_estimator = DecisionTreeClassifier (default value)\nadb_clf.fit(X_train,y_train)\ny_pred = adb_clf.predict(X_test)\ny_score = adb_clf.predict_proba(X_test)[:,1]\n\nmodel_performance('adb_clf')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:48.581557Z","iopub.execute_input":"2023-10-02T09:54:48.582063Z","iopub.status.idle":"2023-10-02T09:54:49.039667Z","shell.execute_reply.started":"2023-10-02T09:54:48.582036Z","shell.execute_reply":"2023-10-02T09:54:49.037646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AdaBoost - Cross Validation - 5 CVs","metadata":{}},{"cell_type":"code","source":"cross_val_metrics(adb_clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:49.041606Z","iopub.execute_input":"2023-10-02T09:54:49.042193Z","iopub.status.idle":"2023-10-02T09:54:57.254356Z","shell.execute_reply.started":"2023-10-02T09:54:49.042161Z","shell.execute_reply":"2023-10-02T09:54:57.253512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n                                  random_state =50, max_features = \"auto\",\n                                  max_leaf_nodes = 30)\nmodel_rf.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model_rf.predict(X_test)\ny_score = model_rf.predict_proba(X_test)[:,1]\nmodel_performance('Model Random Forest')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:54:57.255412Z","iopub.execute_input":"2023-10-02T09:54:57.256125Z","iopub.status.idle":"2023-10-02T09:55:01.934985Z","shell.execute_reply.started":"2023-10-02T09:54:57.256093Z","shell.execute_reply":"2023-10-02T09:55:01.932669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. XG Boost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn import metrics\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nmetrics.accuracy_score(y_test, preds)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:55:01.936334Z","iopub.execute_input":"2023-10-02T09:55:01.937454Z","iopub.status.idle":"2023-10-02T09:55:02.607862Z","shell.execute_reply.started":"2023-10-02T09:55:01.937406Z","shell.execute_reply":"2023-10-02T09:55:02.606943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_performance('Model XG Boost')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T09:55:02.60915Z","iopub.execute_input":"2023-10-02T09:55:02.609989Z","iopub.status.idle":"2023-10-02T09:55:02.704484Z","shell.execute_reply.started":"2023-10-02T09:55:02.609957Z","shell.execute_reply":"2023-10-02T09:55:02.703162Z"},"trusted":true},"execution_count":null,"outputs":[]}]}